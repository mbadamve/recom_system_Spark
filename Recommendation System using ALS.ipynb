{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation System in Spark using ALS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to obtain data and convert into the form which ALS can interpret and generate top k recommendatations. The data of number of songs listened by the user pertaining to Genre, Artist and Language is taken mostly into consideration. The predictions from ALS model will be top k Genres, artists, and languages. Using these items, comparing with the top songs belonging to the item are recommended to the user. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /Users/mahi/opt/anaconda3/lib/python3.7/site-packages (1.5.6)\n",
      "Requirement already satisfied: requests in /Users/mahi/opt/anaconda3/lib/python3.7/site-packages (from kaggle) (2.22.0)\n",
      "Requirement already satisfied: certifi in /Users/mahi/opt/anaconda3/lib/python3.7/site-packages (from kaggle) (2019.9.11)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /Users/mahi/opt/anaconda3/lib/python3.7/site-packages (from kaggle) (1.24.2)\n",
      "Requirement already satisfied: tqdm in /Users/mahi/opt/anaconda3/lib/python3.7/site-packages (from kaggle) (4.36.1)\n",
      "Requirement already satisfied: python-slugify in /Users/mahi/opt/anaconda3/lib/python3.7/site-packages (from kaggle) (4.0.0)\n",
      "Requirement already satisfied: python-dateutil in /Users/mahi/opt/anaconda3/lib/python3.7/site-packages (from kaggle) (2.8.0)\n",
      "Requirement already satisfied: six>=1.10 in /Users/mahi/opt/anaconda3/lib/python3.7/site-packages (from kaggle) (1.12.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/mahi/opt/anaconda3/lib/python3.7/site-packages (from requests->kaggle) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/mahi/opt/anaconda3/lib/python3.7/site-packages (from requests->kaggle) (2.8)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /Users/mahi/opt/anaconda3/lib/python3.7/site-packages (from python-slugify->kaggle) (1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading kkbox-music-recommendation-challenge.zip to /Users/mahi/Documents/GitHub/BDA_Project\n",
      "100%|███████████████████████████████████████▉| 344M/345M [00:19<00:00, 17.7MB/s]\n",
      "100%|████████████████████████████████████████| 345M/345M [00:19<00:00, 18.8MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions download -c kkbox-music-recommendation-challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile(\"kkbox-music-recommendation-challenge.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project_BDA.ipynb\n",
      "README.md\n",
      "Recommendation System using ALS.ipynb\n",
      "kkbox-music-recommendation-challenge.zip\n",
      "members.csv\n",
      "members.csv.7z\n",
      "sample_submission.csv.7z\n",
      "song_extra_info.csv.7z\n",
      "songs.csv.7z\n",
      "test.csv.7z\n",
      "train.csv.7z\n"
     ]
    }
   ],
   "source": [
    "!ls "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately I couldn't get a solution to unzip 7z inside the code. So, the alternative is to unzip the files in the local file explorer. We need train.csv and songs.csv. So we just need to unzip both files and the extracted file can stay in the same working folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Spark session and importing libraries required for running the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql import Row\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below dataframe has data of all songs that exist in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+---------+-------------------+--------------------+-----------+--------+\n",
      "|             song_id|song_length|genre_ids|        artist_name|            composer|   lyricist|language|\n",
      "+--------------------+-----------+---------+-------------------+--------------------+-----------+--------+\n",
      "|CXoTN1eb7AI+DntdU...|     247640|      465|張信哲 (Jeff Chang)|                董貞|     何啟弘|     3.0|\n",
      "|o0kFgae9QtnYgRkVP...|     197328|      444|          BLACKPINK|TEDDY|  FUTURE BO...|      TEDDY|    31.0|\n",
      "|DwVvVurfpuz+XPuFv...|     231781|      465|       SUPER JUNIOR|                null|       null|    31.0|\n",
      "|dKMBWoZyScdxSkihK...|     273554|      465|              S.H.E|              湯小康|     徐世珍|     3.0|\n",
      "|W3bqWd3T+VeHFzHAU...|     140329|      726|           貴族精選|         Traditional|Traditional|    52.0|\n",
      "+--------------------+-----------+---------+-------------------+--------------------+-----------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reading the songs data\n",
    "\n",
    "songs_df = spark.read.option('infer_schema','true').option('header','true').csv('songs.csv')\n",
    "\n",
    "# Showing the top 5 rows\n",
    "\n",
    "songs_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore the dataset to know some stats!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total distinct Genres: 1047\n"
     ]
    }
   ],
   "source": [
    "# Total number of Genres\n",
    "\n",
    "print(\"Total distinct Genres:\", songs_df.select('genre_ids').distinct().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique songs: 2296833\n"
     ]
    }
   ],
   "source": [
    "# Total number of songs.\n",
    "\n",
    "print(\"Total unique songs:\", songs_df.select('song_id').distinct().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique artists: 222409\n"
     ]
    }
   ],
   "source": [
    "# Total number of artists\n",
    "\n",
    "print(\"Total unique artists:\",songs_df.select('artist_name').distinct().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below dataframe has data of all users (msno) and the songs they listened to (song_id) and the source where the song is played. Target column is 0 if the user listens to a song after a month of listening to first song and it is 1 if user listens to another song within a month of song listening event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----------------+-------------------+---------------+------+\n",
      "|                msno|             song_id|source_system_tab| source_screen_name|    source_type|target|\n",
      "+--------------------+--------------------+-----------------+-------------------+---------------+------+\n",
      "|FGtllVqz18RPiwJj/...|BBzumQNXUHKdEBOB7...|          explore|            Explore|online-playlist|     1|\n",
      "|Xumu+NIjS6QYVxDS4...|bhp/MpSNoqoxOIB+/...|       my library|Local playlist more| local-playlist|     1|\n",
      "|Xumu+NIjS6QYVxDS4...|JNWfrrC7zNN7BdMps...|       my library|Local playlist more| local-playlist|     1|\n",
      "|Xumu+NIjS6QYVxDS4...|2A87tzfnJTSWqD7gI...|       my library|Local playlist more| local-playlist|     1|\n",
      "|FGtllVqz18RPiwJj/...|3qm6XTZ6MOCU11x8F...|          explore|            Explore|online-playlist|     1|\n",
      "+--------------------+--------------------+-----------------+-------------------+---------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reading the data of users and songs\n",
    "\n",
    "df = spark.read.option('infer_schema','true').option('header','true').csv('train.csv')\n",
    "\n",
    "# Showing top 5 rows\n",
    "\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information about the above data:\n",
    "1. msno - unique user id\n",
    "2. song_id - unique song id\n",
    "3. source_system_tab - the source or tab in the app where song was played\n",
    "4. source_screen_name - name of the source or tab in the app\n",
    "5. source_type - type of source\n",
    "6. target - listening event in a month (1) or later(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique users: 30755\n"
     ]
    }
   ],
   "source": [
    "# Total number of distinct users \n",
    "\n",
    "print(\"Total number of unique users:\",df.select('msno').distinct().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows: 7377418\n"
     ]
    }
   ],
   "source": [
    "# Total number of rows in data to know the volume of data we are dealing with\n",
    "print(\"Total number of rows:\", df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of listening events in a month: 3714656\n"
     ]
    }
   ],
   "source": [
    "# Total number of monthly listening events of users\n",
    "\n",
    "print(\"Total number of listening events in a month:\",df.where(df.target==1).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users who listened to a song after a month: 3662762\n"
     ]
    }
   ],
   "source": [
    "# Total number of listening events with last listening event occured a month ago\n",
    "\n",
    "print(\"Users who listened to a song after a month:\",df.where(df.target == 0).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above it is understood that the number of observations we are dealing with is huge and it is required to work with only a sample of observations.We now create a sample of data to use because the number of rows to compute is huge for even spark and will take longer times and due to computational restrictions we would use sampling from the data to derive predictions. The same idea can be implemented for every other sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73929"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sampling the dataset of size 1% since this 1% itself has 73929 rows to deal with.\n",
    "\n",
    "df_sample = df.sample(0.01)\n",
    "df_sample.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of target = 1: 0.49907343532308024\n"
     ]
    }
   ],
   "source": [
    "# The data has even distribution of 1 and 0\n",
    "\n",
    "print(\"Proportion of target = 1:\", df_sample.where(df_sample.target == 1).count()/df_sample.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of target = 0: 0.5009265646769198\n"
     ]
    }
   ],
   "source": [
    "print(\"Proportion of target = 0:\", df_sample.where(df_sample.target == 0).count()/df_sample.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data now needs to be prepared for feeding into ALS recommender system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(msno='MXIMDXO0j3UpaT7FvOSGW6Y5zfhlh+xYjTqGoUdMzEE=', count=62),\n",
       " Row(msno='KGXNZ/H3VxvET/+rGxlrAe7Gpz2eKMXyuSg3xh8Ij1M=', count=55),\n",
       " Row(msno='FGtllVqz18RPiwJj/edr2gV78zirAiY/9SmYvia+kCg=', count=54),\n",
       " Row(msno='cqjRBV/jWN2ujhc+z/4tz+Mj6xEfflAAt6qBXCqxKvw=', count=50),\n",
       " Row(msno='SZ5NNypqaTWljFO1HiVZwkw3713+rM9x/JNdJd8/fzc=', count=40),\n",
       " Row(msno='hYJpPvGod6vy09TnlXdQe3Q0vlxju5u5Ruf8V2XkTio=', count=39),\n",
       " Row(msno='OOUnJuX4SteRhUdJZ9B2DqtfiwsfcZVBefEhXLeBsFg=', count=38),\n",
       " Row(msno='o+5RNlSWrzvrphgBNGIo1FLkGxBgyICns6qXj3nS7Pk=', count=38),\n",
       " Row(msno='LThaiVqGGnVTPmTcmwN/LLo4fVb5dzkduzd7s1SgzIA=', count=37),\n",
       " Row(msno='gxxBbzV3eE2XGjUrFVB2FzAve55Oe1s86HD+OEh36Gw=', count=35)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It is shown the number of songs listened by each user in the sample\n",
    "\n",
    "df_sample.groupBy('msno').count().orderBy('count', ascending = False).take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users have listened to songs with a maximum of 62."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+---------+-------------------+--------------------+-----------+--------+\n",
      "|             song_id|song_length|genre_ids|        artist_name|            composer|   lyricist|language|\n",
      "+--------------------+-----------+---------+-------------------+--------------------+-----------+--------+\n",
      "|CXoTN1eb7AI+DntdU...|     247640|      465|張信哲 (Jeff Chang)|                董貞|     何啟弘|     3.0|\n",
      "|o0kFgae9QtnYgRkVP...|     197328|      444|          BLACKPINK|TEDDY|  FUTURE BO...|      TEDDY|    31.0|\n",
      "|DwVvVurfpuz+XPuFv...|     231781|      465|       SUPER JUNIOR|                null|       null|    31.0|\n",
      "|dKMBWoZyScdxSkihK...|     273554|      465|              S.H.E|              湯小康|     徐世珍|     3.0|\n",
      "|W3bqWd3T+VeHFzHAU...|     140329|      726|           貴族精選|         Traditional|Traditional|    52.0|\n",
      "+--------------------+-----------+---------+-------------------+--------------------+-----------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Coming back to songs data\n",
    "\n",
    "songs_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the column genre_ids, it is seen that a song may belong to multiple genre ids, and are separated by | in the cell. They need to added as a new observation with other values of other columns keeping intact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['465',\n",
       " '444',\n",
       " '465',\n",
       " '465',\n",
       " '726',\n",
       " '864|857|850|843',\n",
       " '458',\n",
       " '465',\n",
       " '465',\n",
       " '352|1995',\n",
       " '2157',\n",
       " '465',\n",
       " '726',\n",
       " '458',\n",
       " '359']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Genre ids have multiple entries in same cell which means a song belonging to multiple genres\n",
    "\n",
    "songs_df.select('genre_ids').rdd.map(lambda x:x.genre_ids).take(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(genre='465'),\n",
       " Row(genre='444'),\n",
       " Row(genre='465'),\n",
       " Row(genre='465'),\n",
       " Row(genre='726'),\n",
       " Row(genre='864'),\n",
       " Row(genre='857'),\n",
       " Row(genre='850'),\n",
       " Row(genre='843'),\n",
       " Row(genre='458'),\n",
       " Row(genre='465'),\n",
       " Row(genre='465'),\n",
       " Row(genre='352'),\n",
       " Row(genre='1995'),\n",
       " Row(genre='2157'),\n",
       " Row(genre='465'),\n",
       " Row(genre='726'),\n",
       " Row(genre='458'),\n",
       " Row(genre='359'),\n",
       " Row(genre='359')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting into individual genre and repeating song entry\n",
    "\n",
    "songs_df = songs_df.withColumn('genre',explode(split(songs_df.genre_ids, \"\\|\")))\n",
    "\n",
    "songs_df.select('genre').take(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, user and song data needs to merged to identify the genre, artists and language of songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----------------+--------------------+---------------+------+-----------+---------+-----------+--------------------+--------+--------+-----+\n",
      "|             song_id|                msno|source_system_tab|  source_screen_name|    source_type|target|song_length|genre_ids|artist_name|            composer|lyricist|language|genre|\n",
      "+--------------------+--------------------+-----------------+--------------------+---------------+------+-----------+---------+-----------+--------------------+--------+--------+-----+\n",
      "|o0kFgae9QtnYgRkVP...|kPgqI5lBSLx9/RUjC...|       my library|          My library|  local-library|     0|     197328|      444|  BLACKPINK|TEDDY|  FUTURE BO...|   TEDDY|    31.0|  444|\n",
      "|o0kFgae9QtnYgRkVP...|tieAKb/19RM0CnPQx...|       my library| Local playlist more|  local-library|     1|     197328|      444|  BLACKPINK|TEDDY|  FUTURE BO...|   TEDDY|    31.0|  444|\n",
      "|o0kFgae9QtnYgRkVP...|Qr8Cbh9/qXRCaQDpo...|         discover|Online playlist more|online-playlist|     1|     197328|      444|  BLACKPINK|TEDDY|  FUTURE BO...|   TEDDY|    31.0|  444|\n",
      "|o0kFgae9QtnYgRkVP...|IhuRO/koBAuk6Ha7c...|       my library| Local playlist more|  local-library|     0|     197328|      444|  BLACKPINK|TEDDY|  FUTURE BO...|   TEDDY|    31.0|  444|\n",
      "|o0kFgae9QtnYgRkVP...|XyVs4cnySFeVCGZro...|       my library| Local playlist more| local-playlist|     0|     197328|      444|  BLACKPINK|TEDDY|  FUTURE BO...|   TEDDY|    31.0|  444|\n",
      "+--------------------+--------------------+-----------------+--------------------+---------------+------+-----------+---------+-----------+--------------------+--------+--------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cut = df_sample.join(songs_df, 'song_id')\n",
    "df_cut.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see how many songs in each Genre the user listened to. So the count of genre becomes the Genre interest of the user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is done for this aggregation procedure is, \n",
    "1. Grouping the data by msno, genre.\n",
    "2. Aggregating with 'count'\n",
    "3. Converting to RDD to perform Map function\n",
    "4. Converting back to dataframe with columns User, genre, genre_interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------+\n",
      "|                User|genre|genre_interest|\n",
      "+--------------------+-----+--------------+\n",
      "|KGXNZ/H3VxvET/+rG...|  465|            38|\n",
      "|cqjRBV/jWN2ujhc+z...|  465|            31|\n",
      "|MXIMDXO0j3UpaT7Fv...|  465|            30|\n",
      "|FGtllVqz18RPiwJj/...|  465|            26|\n",
      "|dU4RbzpIRRd/EkA9X...|  465|            25|\n",
      "+--------------------+-----+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating a dataframe with the genre interest of each user\n",
    "\n",
    "user_genre = df_cut.select('msno','genre').groupBy('msno',\n",
    "                                                   'genre').count().rdd.map(lambda x: x).toDF(['User', \n",
    "                                                                                               'genre', 'genre_interest'])\n",
    "\n",
    "user_genre.orderBy('genre_interest', ascending=False).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly we do for artist interest and language interest and the dataframes of each are shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------------+---------------+\n",
      "|                User|              artist_name|artist_interest|\n",
      "+--------------------+-------------------------+---------------+\n",
      "|MXIMDXO0j3UpaT7Fv...|証聲音樂圖書館 ECHO MUSIC|             12|\n",
      "|s59i0bBkU2+a9l66j...|          Various Artists|             10|\n",
      "|2tmUzRCcD0l3et0ck...|証聲音樂圖書館 ECHO MUSIC|              8|\n",
      "|N+/5izDHnbJo+15dP...|          Various Artists|              8|\n",
      "|n7pT0Hb9KHJCHZgp0...|          Various Artists|              8|\n",
      "+--------------------+-------------------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Artist interest\n",
    "\n",
    "user_artist = df_cut.select('msno','artist_name').groupBy('msno',\n",
    "                                                          'artist_name').count().rdd.map(lambda x: x).toDF(['User', \n",
    "                                                                                                            'artist_name', 'artist_interest'])\n",
    "\n",
    "user_artist.orderBy('artist_interest', ascending=False).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+-----------------+\n",
      "|                User|language|language_interest|\n",
      "+--------------------+--------+-----------------+\n",
      "|MXIMDXO0j3UpaT7Fv...|    52.0|               50|\n",
      "|cqjRBV/jWN2ujhc+z...|     3.0|               40|\n",
      "|SZ5NNypqaTWljFO1H...|    52.0|               36|\n",
      "|DqwB7smOAIbNnnQbW...|    52.0|               34|\n",
      "|FGtllVqz18RPiwJj/...|    52.0|               31|\n",
      "+--------------------+--------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Language Interest\n",
    "\n",
    "user_language = df_cut.select('msno','language').groupBy('msno',\n",
    "                                                         'language').count().rdd.map(lambda x: x).toDF(['User', \n",
    "                                                                                                        'language', 'language_interest'])\n",
    "\n",
    "user_language.orderBy('language_interest', ascending=False).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, now the approach is to find popular songs in each Genre to recommend to the user. The reason for this is, we find the top Genres the user might be interested in and later we find the top songs of the genre and recommend the one user hadn't listened to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+---------------------+\n",
      "|genre|                song|genre_song_popularity|\n",
      "+-----+--------------------+---------------------+\n",
      "|  458|reXuGcEWDDCnL0K3T...|                  144|\n",
      "|  458|FynUyq0+drmIARmK1...|                  137|\n",
      "|  458|cy10N2j2sdY/X4BDU...|                  134|\n",
      "|  458|T86YHdD4C9JSc274b...|                  134|\n",
      "|  465|wBTWuHbjdjxnG1lQc...|                  127|\n",
      "+-----+--------------------+---------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aggregating the dataframe to find songs popular in each Genre\n",
    "\n",
    "genre_pop = df_cut.select('genre','song_id','msno').groupBy('genre',\n",
    "                                                            'song_id').count().rdd.map(lambda x: x).toDF(['genre', \n",
    "                                                                                                          'song', 'genre_song_popularity'])\n",
    "genre_pop.orderBy('genre_song_popularity', ascending=False).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------------------+\n",
      "|         artist_name|                song|artist_song_popularity|\n",
      "+--------------------+--------------------+----------------------+\n",
      "|         Alan Walker|J4qKkLIoW7aYACuTu...|                   248|\n",
      "|         Alan Walker|v/3onppBGoSpGsWb8...|                   182|\n",
      "|         Alan Walker|zHqZ07gn+YvF36FWz...|                   156|\n",
      "|周湯豪 (NICKTHEREAL)|reXuGcEWDDCnL0K3T...|                   144|\n",
      "|         Eric 周興哲|FynUyq0+drmIARmK1...|                   137|\n",
      "+--------------------+--------------------+----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aggregating the dataframe to find songs popular for each artist\n",
    "\n",
    "artist_pop = df_cut.select('artist_name','song_id','msno').groupBy('artist_name',\n",
    "                                                                   'song_id').count().rdd.map(lambda x: x).toDF(['artist_name', \n",
    "                                                                                                                 'song', 'artist_song_popularity'])\n",
    "artist_pop.orderBy('artist_song_popularity', ascending=False).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+------------------------+\n",
      "|language|                song|language_song_popularity|\n",
      "+--------+--------------------+------------------------+\n",
      "|    52.0|J4qKkLIoW7aYACuTu...|                     248|\n",
      "|    52.0|v/3onppBGoSpGsWb8...|                     182|\n",
      "|    52.0|zHqZ07gn+YvF36FWz...|                     156|\n",
      "|     3.0|reXuGcEWDDCnL0K3T...|                     144|\n",
      "|     3.0|FynUyq0+drmIARmK1...|                     137|\n",
      "+--------+--------------------+------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aggregating the dataframe to find songs popular in each language\n",
    "\n",
    "language_pop = df_cut.select('language','song_id','msno').groupBy('language',\n",
    "                                                                  'song_id').count().rdd.map(lambda x: x).toDF(['language', \n",
    "                                                                                                                'song', 'language_song_popularity'])\n",
    "language_pop.orderBy('language_song_popularity', ascending=False).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct Genres in the sample dataset: 108\n"
     ]
    }
   ],
   "source": [
    "# Distinct Genres in the data\n",
    "\n",
    "print(\"Distinct Genres in the sample dataset:\",df_cut.select('genre').distinct().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct users in the sample dataset: 18684\n"
     ]
    }
   ],
   "source": [
    "# Distinct users in the data\n",
    "\n",
    "print(\"Distinct users in the sample dataset:\",df_cut.select('msno').distinct().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's combine all the three dataframes of users to see the interest of each user in the categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------+--------------------+---------------+--------+-----------------+\n",
      "|                User|genre|genre_interest|         artist_name|artist_interest|language|language_interest|\n",
      "+--------------------+-----+--------------+--------------------+---------------+--------+-----------------+\n",
      "|KGXNZ/H3VxvET/+rG...|  465|            38|           Shy Girls|              2|     3.0|               26|\n",
      "|KGXNZ/H3VxvET/+rG...|  465|            38|   林宥嘉 (Yoga Lin)|              2|     3.0|               26|\n",
      "|KGXNZ/H3VxvET/+rG...|  465|            38|             BIGBANG|              2|     3.0|               26|\n",
      "|KGXNZ/H3VxvET/+rG...|  465|            38|蜂蜜幸運草電視原聲帶|              2|     3.0|               26|\n",
      "|KGXNZ/H3VxvET/+rG...|  465|            38|            Maroon 5|              2|     3.0|               26|\n",
      "+--------------------+-----+--------------+--------------------+---------------+--------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# User vs Genre interest and Artist interest and language interest\n",
    "\n",
    "User_side = user_genre.join(user_artist, \"User\", 'outer').join(user_language, 'User','outer')\n",
    "\n",
    "User_side.orderBy(['genre_interest', \n",
    "                   'artist_interest', \n",
    "                   'language_interest'], ascending = False).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the popular songs in each of these categories. We won't using these dataframes but to have an idea of how it looks when we have statistics of users and songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+---------------------+--------------------+----------------------+--------+------------------------+\n",
      "|                song|genre|genre_song_popularity|         artist_name|artist_song_popularity|language|language_song_popularity|\n",
      "+--------------------+-----+---------------------+--------------------+----------------------+--------+------------------------+\n",
      "|reXuGcEWDDCnL0K3T...|  458|                  144|周湯豪 (NICKTHEREAL)|                   144|     3.0|                     144|\n",
      "|FynUyq0+drmIARmK1...|  458|                  137|         Eric 周興哲|                   137|     3.0|                     137|\n",
      "|T86YHdD4C9JSc274b...|  458|                  134|   周杰倫 (Jay Chou)|                   134|     3.0|                     134|\n",
      "|cy10N2j2sdY/X4BDU...|  458|                  134|     五月天 (Mayday)|                   134|     3.0|                     134|\n",
      "|M9rAajz4dYuRhZ7jL...|  465|                  127|     林俊傑 (JJ Lin)|                   127|     3.0|                     127|\n",
      "+--------------------+-----+---------------------+--------------------+----------------------+--------+------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Popular songs in each category\n",
    "\n",
    "song_side = genre_pop.join(artist_pop, 'song', 'outer').join(language_pop, \"song\", 'outer')\n",
    "\n",
    "song_side.orderBy(['genre_song_popularity', \n",
    "                   'artist_song_popularity', \n",
    "                   'language_song_popularity'], ascending = False).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Song Recommendations using ALS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to index the columns in the data to feed into the ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We would use the StringIndexer to achieve this\n",
    "\n",
    "indexer = StringIndexer(inputCol = \"User\", outputCol=\"UserIndex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String Indexed dataframe\n",
    "\n",
    "indexed = indexer.fit(user_genre).transform(user_genre).drop('User')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------+---------+\n",
      "|genre|genre_interest|UserIndex|\n",
      "+-----+--------------+---------+\n",
      "|  465|             1|   5645.0|\n",
      "|  465|             8|    137.0|\n",
      "|  444|             1|   2580.0|\n",
      "|  465|             3|  10715.0|\n",
      "|  465|             5|    286.0|\n",
      "+-----+--------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# we use this kind of dataframe for generating predictions and it is the format preferred for ALS\n",
    "\n",
    "indexed.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+--------------+\n",
      "|genre_id|UserIndex|genre_interest|\n",
      "+--------+---------+--------------+\n",
      "|     465|     5645|             1|\n",
      "|     465|      137|             8|\n",
      "|     444|     2580|             1|\n",
      "|     465|    10715|             3|\n",
      "|     465|      286|             5|\n",
      "+--------+---------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# the index, genre should be integer, so we cast these columns as int\n",
    "\n",
    "indexed = indexed.selectExpr('cast(genre as int) as genre_id', \n",
    "                             'cast(UserIndex as int)', \n",
    "                             'genre_interest')\n",
    "indexed.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- genre_id: integer (nullable = true)\n",
      " |-- UserIndex: integer (nullable = true)\n",
      " |-- genre_interest: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexed.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into training and testing\n",
    "training, test = indexed.randomSplit([0.8,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the ALS\n",
    "als = ALS()\\\n",
    ".setMaxIter(5)\\\n",
    ".setRegParam(0.01)\\\n",
    ".setUserCol(\"UserIndex\")\\\n",
    ".setItemCol(\"genre_id\")\\\n",
    ".setRatingCol(\"genre_interest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: alpha for implicit preference (default: 1.0)\n",
      "checkpointInterval: set checkpoint interval (>= 1) or disable checkpoint (-1). E.g. 10 means that the cache will get checkpointed every 10 iterations. Note: this setting will be ignored if the checkpoint directory is not set in the SparkContext. (default: 10)\n",
      "coldStartStrategy: strategy for dealing with unknown or new users/items at prediction time. This may be useful in cross-validation or production scenarios, for handling user/item ids the model has not seen in the training data. Supported values: 'nan', 'drop'. (default: nan)\n",
      "finalStorageLevel: StorageLevel for ALS model factors. (default: MEMORY_AND_DISK)\n",
      "implicitPrefs: whether to use implicit preference (default: False)\n",
      "intermediateStorageLevel: StorageLevel for intermediate datasets. Cannot be 'NONE'. (default: MEMORY_AND_DISK)\n",
      "itemCol: column name for item ids. Ids must be within the integer value range. (default: item, current: genre_id)\n",
      "maxIter: max number of iterations (>= 0). (default: 10, current: 5)\n",
      "nonnegative: whether to use nonnegative constraint for least squares (default: False)\n",
      "numItemBlocks: number of item blocks (default: 10)\n",
      "numUserBlocks: number of user blocks (default: 10)\n",
      "predictionCol: prediction column name. (default: prediction)\n",
      "rank: rank of the factorization (default: 10)\n",
      "ratingCol: column name for ratings (default: rating, current: genre_interest)\n",
      "regParam: regularization parameter (>= 0). (default: 0.1, current: 0.01)\n",
      "seed: random seed. (default: 1752233489337793335)\n",
      "userCol: column name for user ids. Ids must be within the integer value range. (default: user, current: UserIndex)\n"
     ]
    }
   ],
   "source": [
    "# Below are the hyperparameters can be added to ALS\n",
    "print(als.explainParams())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the ALS\n",
    "alsModel = als.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating Predictions\n",
    "predictions = alsModel.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------+\n",
      "|UserIndex|      recommended|\n",
      "+---------+-----------------+\n",
      "|     1580| [545, 7.8692727]|\n",
      "|     1580|[1995, 5.6934133]|\n",
      "|     1580|[2086, 5.2582836]|\n",
      "|     1580|  [850, 4.759304]|\n",
      "|     1580|[1572, 4.7450814]|\n",
      "|     1580|  [481, 4.554379]|\n",
      "|     1580| [873, 4.4750085]|\n",
      "|     1580|  [516, 4.389927]|\n",
      "|     1580|  [465, 3.836222]|\n",
      "|     1580| [388, 3.2870884]|\n",
      "+---------+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# So for each user, we get 10 top recommended Genres\n",
    "recomm_genre = alsModel.recommendForAllUsers(10).selectExpr('UserIndex', 'explode(recommendations) as recommended')\n",
    "recomm_genre.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[545, 1995, 2086, 850, 1572, 481, 873, 516, 465, 388]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generated predictions\n",
    "top_genre_user = recomm_genre.where(recomm_genre.UserIndex == 1580).rdd.map(lambda x: x.recommended).map(lambda x: x.genre_id).collect()\n",
    "top_genre_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                song|\n",
      "+--------------------+\n",
      "|UMzNsDKRVjcNUYhlT...|\n",
      "|Sbz9GfHVOAERJA7o4...|\n",
      "|1iHRL+cugxRVTz0Zb...|\n",
      "|KnZV077x3kJoBnJm/...|\n",
      "|d90L+EZxCshVGS4rU...|\n",
      "|5DfRZqAreMU3ovigj...|\n",
      "|lTvKbkQhBBLCYrVyR...|\n",
      "|fh+mNN016KM5hFM7D...|\n",
      "|9LaJP77sG3MTpRIDO...|\n",
      "|sjXtOEX2/uwyf36Y5...|\n",
      "+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# song recommendations\n",
    "song_side.sort('genre', 'genre_song_popularity', ascending=False).where(song_side.genre == top_genre_user[1]).select('song').show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Song recommendations based on Artist user is interested in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting columns via string indexing\n",
    "indexer = StringIndexer(inputCol = \"User\", outputCol=\"UserIndex\")\n",
    "indexer_artist = StringIndexer(inputCol = 'artist_name', outputCol = 'artist_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_artist = indexer.fit(user_artist).transform(user_artist)\n",
    "indexed_artist = indexer_artist.fit(indexed_artist).transform(indexed_artist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+---------------+---------+------------+\n",
      "|                User|         artist_name|artist_interest|UserIndex|artist_index|\n",
      "+--------------------+--------------------+---------------+---------+------------+\n",
      "|GH5CcteDnxOzg5zkI...|  信樂團 (Shin Band)|              1|    630.0|       120.0|\n",
      "|S7FV7CKTmx2ymejZJ...|      Rag'N'Bone Man|              1|    541.0|      1400.0|\n",
      "|5fFQq48H5HIiyfYkk...|   Peter Paul & Mary|              1|  11529.0|      4717.0|\n",
      "|K5x68e9t0PySwLAoe...|周湯豪 (NICKTHEREAL)|              1|   3066.0|        26.0|\n",
      "|4Lxw2WOLQw7LBrp6W...|              詹雅雯|              1|   9940.0|       206.0|\n",
      "+--------------------+--------------------+---------------+---------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexed_artist.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+---------------+--------------------+\n",
      "|artist_index|UserIndex|artist_interest|         artist_name|\n",
      "+------------+---------+---------------+--------------------+\n",
      "|         120|      630|              1|  信樂團 (Shin Band)|\n",
      "|        1400|      541|              1|      Rag'N'Bone Man|\n",
      "|        4717|    11529|              1|   Peter Paul & Mary|\n",
      "|          26|     3066|              1|周湯豪 (NICKTHEREAL)|\n",
      "|         206|     9940|              1|              詹雅雯|\n",
      "+------------+---------+---------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexed_artist_als = indexed_artist.selectExpr('cast(artist_index as int)', 'cast(UserIndex as int)', 'artist_interest', 'artist_name')\n",
    "indexed_artist_als.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_artist, test_artist = indexed_artist_als.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "als = ALS()\\\n",
    ".setMaxIter(5)\\\n",
    ".setRegParam(0.01)\\\n",
    ".setUserCol(\"UserIndex\")\\\n",
    ".setItemCol(\"artist_index\")\\\n",
    ".setRatingCol(\"artist_interest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "alsModel_artist = als.fit(training_artist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = alsModel_artist.transform(test_artist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------+\n",
      "|UserIndex|      recommended|\n",
      "+---------+-----------------+\n",
      "|     1580| [1651, 4.933778]|\n",
      "|     1580| [633, 4.1720943]|\n",
      "|     1580|  [828, 3.925313]|\n",
      "|     1580|[1781, 3.5492597]|\n",
      "|     1580|[1559, 3.5222251]|\n",
      "|     1580|[1094, 3.5146184]|\n",
      "|     1580|[1118, 3.4517207]|\n",
      "|     1580| [764, 3.4117632]|\n",
      "|     1580|[1713, 3.3856668]|\n",
      "|     1580| [2444, 3.355938]|\n",
      "+---------+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Recommended artists(string indexed values)\n",
    "recomm_artist = alsModel_artist.recommendForAllUsers(10).selectExpr('UserIndex', 'explode(recommendations) as recommended')\n",
    "recomm_artist.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+\n",
      "|artist_index|            rating|\n",
      "+------------+------------------+\n",
      "|         637| 4.602288246154785|\n",
      "|         603|4.6009321212768555|\n",
      "|        1603| 4.285262107849121|\n",
      "|         497| 4.222316265106201|\n",
      "|         479|  4.03449010848999|\n",
      "|         686| 4.012558460235596|\n",
      "|         971| 4.010550022125244|\n",
      "|        1354| 3.862031936645508|\n",
      "|         498| 3.829875946044922|\n",
      "|         594|3.8296868801116943|\n",
      "+------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# string indexed artists\n",
    "top_artist_user = recomm_artist.where(recomm_artist.UserIndex == 1580).rdd.map(lambda x: x.recommended).collect()#map(lambda x: x.artist_index).collect()\n",
    "artist_user = sc.parallelize(top_artist_user).toDF()\n",
    "artist_user.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Muse',\n",
       " '約書亞樂團',\n",
       " 'Richard Clayderman',\n",
       " 'Eir Aoi (藍井エイル)',\n",
       " 'SCANDAL',\n",
       " 'High School Musical Original Soundtrack',\n",
       " 'Gallant x Tablo x Eric Nam',\n",
       " 'Ella Fitzgerald',\n",
       " 'Nogizaka46 (乃木坂46)',\n",
       " '滾石金韻民歌百大精選']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obtaining artist names from above\n",
    "recomm_artists = indexed_artist.select(indexed_artist.artist_index.cast('int'), 'artist_name').join(artist_user, \"artist_index\", 'inner').distinct().rdd.map(\n",
    "lambda x: x.artist_name).collect()\n",
    "recomm_artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                song|\n",
      "+--------------------+\n",
      "|s8KQo0qsDIS42y5xg...|\n",
      "|sOYNImNuRdogfOvo9...|\n",
      "|s8KQo0qsDIS42y5xg...|\n",
      "|cR3/3Zf2wzp9uQteN...|\n",
      "|t/HLyst7l4EjgPCuQ...|\n",
      "|gJwLE8jSKMh2YEuLX...|\n",
      "|QLDzqRYCPufbZve5u...|\n",
      "|1fruU7bvpRMfDMkco...|\n",
      "|2hyXkI5tyKL0oEkTS...|\n",
      "|FHLjRKekX6BnbLjDj...|\n",
      "+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# recommended songs based on artists\n",
    "song_side.sort('artist_name', 'artist_song_popularity', ascending=False).where(song_side.artist_name == recomm_artists[1]).select('song').show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Song recommendations based on language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = StringIndexer(inputCol = \"User\", outputCol=\"UserIndex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_language = indexer.fit(user_language).transform(user_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+-----------------+\n",
      "|language|UserIndex|language_interest|\n",
      "+--------+---------+-----------------+\n",
      "|       3|    719.0|                7|\n",
      "|      52|   1305.0|                3|\n",
      "|      52|  15835.0|                2|\n",
      "|       3|    614.0|                5|\n",
      "|       3|   1077.0|                9|\n",
      "|       3|   3951.0|                2|\n",
      "|      52|    108.0|               11|\n",
      "|      52|  11014.0|                1|\n",
      "|       3|   7422.0|                1|\n",
      "|       3|   9733.0|                5|\n",
      "|      52|  12981.0|                1|\n",
      "|      52|   7342.0|                1|\n",
      "|      52|    615.0|                5|\n",
      "|       3|  16188.0|                2|\n",
      "|      -1|   3441.0|                1|\n",
      "|       3|  13053.0|                3|\n",
      "|       3|   7082.0|                4|\n",
      "|      52|   7750.0|                4|\n",
      "|       3|   9763.0|                2|\n",
      "|      52|    510.0|                4|\n",
      "+--------+---------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexed_language = indexed_language.select(indexed_language.language.cast('int'), 'UserIndex', 'language_interest')\n",
    "indexed_language.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_language = indexed_language.fillna({'language':'0'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "als = ALS()\\\n",
    ".setMaxIter(5)\\\n",
    ".setRegParam(0.01)\\\n",
    ".setUserCol(\"UserIndex\")\\\n",
    ".setItemCol(\"language\")\\\n",
    ".setRatingCol(\"language_interest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_language, test_language = indexed_language.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "alsModel_language = als.fit(training_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = alsModel_language.transform(test_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------+\n",
      "|UserIndex|     recommended|\n",
      "+---------+----------------+\n",
      "|     1580|  [3, 3.7705626]|\n",
      "|     1580| [52, 1.8470466]|\n",
      "|     1580| [24, 0.9479289]|\n",
      "|     1580|  [10, 0.895591]|\n",
      "|     1580|[45, 0.89142084]|\n",
      "|     1580| [59, 0.8420744]|\n",
      "|     1580| [38, 0.6820886]|\n",
      "|     1580|[31, 0.57250977]|\n",
      "|     1580|[17, 0.54873055]|\n",
      "|     1580|[-1, 0.36088538]|\n",
      "+---------+----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Top k languages recommended for the user\n",
    "recomm_language = alsModel_language.recommendForAllUsers(10).selectExpr('UserIndex', 'explode(recommendations) as recommended')\n",
    "recomm_language.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 52, 24, 10, 45, 59, 38, 31, 17, -1]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 10 languages for a user\n",
    "top_languages_user = recomm_language.where(recomm_language.UserIndex == 1580).rdd.map(lambda x: x.recommended).map(lambda x: x.language).collect()\n",
    "top_languages_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                song|\n",
      "+--------------------+\n",
      "|J4qKkLIoW7aYACuTu...|\n",
      "|J4qKkLIoW7aYACuTu...|\n",
      "|v/3onppBGoSpGsWb8...|\n",
      "|v/3onppBGoSpGsWb8...|\n",
      "|zHqZ07gn+YvF36FWz...|\n",
      "|zHqZ07gn+YvF36FWz...|\n",
      "|+LztcJcPEEwsikk6+...|\n",
      "|IKMFuL0f5Y8c63Hg9...|\n",
      "|9YYrODwrXpDcCjOJy...|\n",
      "|9YYrODwrXpDcCjOJy...|\n",
      "+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Recommended songs.\n",
    "song_side.sort('language', 'language_song_popularity', ascending=False).where(song_side.language == top_languages_user[1]).select('song').show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is not evaluated using RMSE since we not completely have values for each user and the predictions since some users might not have rated the item. The recommendations are completely new songs which user havent discovered yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The ALS model is used widely by many companies for making recommendations but the ALS is not completely used as an only tool. It is combined with many collaborative filtering models to obtain near predictions of items.\n",
    "2. Recommender systems are difficult to evaluate: if some classical metrics such that MSE, accuracy, recall or precision can be used, one should keep in mind that some desired properties such as diversity (serendipity) and explainability can’t be assessed this way ; real conditions evaluation (like A/B testing or sample testing) is finally the only real way to evaluate a new recommender system but requires a certain confidence in the model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
